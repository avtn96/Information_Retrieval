# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kCI2K_vMPEOiSoJDWdri6WQFZZvNPzZG
"""

import numpy as np
import networkx as nx
import matplotlib.pyplot as plt

def create_adjacency_matrix(urls, links):
    """
    Create an adjacency matrix from the list of URLs and their links.
    """
    n = len(urls)
    adjacency_matrix = np.zeros((n, n))

    url_to_index = {url: idx for idx, url in enumerate(urls)}

    for url, out_links in links.items():
        if url in url_to_index:
            row = url_to_index[url]
            for link in out_links:
                if link in url_to_index:
                    col = url_to_index[link]
                    adjacency_matrix[row, col] = 1

    return adjacency_matrix

def calculate_page_rank(adjacency_matrix, d=0.85, max_iterations=100, tol=1e-6):
    """
    Calculate the PageRank for each page.
    """
    n = adjacency_matrix.shape[0]
    out_link_counts = adjacency_matrix.sum(axis=1)

    # Create the Google matrix
    G = np.zeros((n, n))
    for i in range(n):
        for j in range(n):
            if out_link_counts[i] == 0:
                G[i, j] = 1.0 / n
            else:
                G[i, j] = adjacency_matrix[i, j] / out_link_counts[i]

    M = d * G + (1 - d) / n

    # Initialize the PageRank vector
    pr = np.ones(n) / n

    for iteration in range(max_iterations):
        new_pr = M.T @ pr
        if np.linalg.norm(new_pr - pr) < tol:
            print(f"Converged after {iteration + 1} iterations")
            break
        pr = new_pr

    return pr

def draw_graph(urls, links, page_rank):
    """
    Draw a graph showing the interconnections between pages.
    """
    G = nx.DiGraph()

    # Extract movie names from URLs
    movie_names = [url.split('/')[-1].replace('_', ' ').title() for url in urls]

    # Add nodes with PageRank as a node attribute
    for url, name, rank in zip(urls, movie_names, page_rank):
        G.add_node(name, pagerank=rank)

    # Add edges
    for url, out_links in links.items():
        for link in out_links:
            G.add_edge(url.split('/')[-1].replace('_', ' ').title(), link.split('/')[-1].replace('_', ' ').title())

    # Get positions for all nodes
    pos = nx.spring_layout(G, k=0.5, iterations=50)

    # Draw the nodes with sizes proportional to their PageRank
    node_sizes = [10000 * G.nodes[name]['pagerank'] for name in G]
    plt.figure(figsize=(14, 14))  # Increase figure size
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue')

    # Draw the edges
    nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=20, edge_color='gray')

    # Draw the labels
    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')

    plt.title("Interconnections Between Rotten Tomatoes Pages")
    plt.show()

if __name__ == "__main__":
    # Example URLs and their links (to be replaced with actual data)
    urls = [
         "https://www.rottentomatoes.com/m/asteroid_city",
         "https://www.rottentomatoes.com/m/a_man_called_otto",
         "https://www.rottentomatoes.com/m/the_contestant",
         "https://www.rottentomatoes.com/m/the_hatchet_wielding_hitchhiker",
         "https://www.rottentomatoes.com/m/to_kill_a_tiger",
         "https://www.rottentomatoes.com/m/this_much_we_know",
         "https://www.rottentomatoes.com/m/boston_strangler_2023",
         "https://www.rottentomatoes.com/m/killers_of_the_flower_moon",
         "https://www.rottentomatoes.com/m/reptile_2023",
         "https://www.rottentomatoes.com/m/pain_hustlers"
    ]

    links = {
        "https://www.rottentomatoes.com/m/asteroid_city": ["https://www.rottentomatoes.com/m/a_man_called_otto"],
        "https://www.rottentomatoes.com/m/a_man_called_otto": [],
        "https://www.rottentomatoes.com/m/the_contestant": ["https://www.rottentomatoes.com/m/the_hatchet_wielding_hitchhiker", "https://www.rottentomatoes.com/m/to_kill_a_tiger"],
        "https://www.rottentomatoes.com/m/the_hatchet_wielding_hitchhiker": ["https://www.rottentomatoes.com/m/this_much_we_know"],
        "https://www.rottentomatoes.com/m/to_kill_a_tiger": [],
        "https://www.rottentomatoes.com/m/this_much_we_know": ["https://www.rottentomatoes.com/m/the_hatchet_wielding_hitchhiker"],
        "https://www.rottentomatoes.com/m/boston_strangler_2023": ["https://www.rottentomatoes.com/m/killers_of_the_flower_moon", "https://www.rottentomatoes.com/m/reptile_2023", "https://www.rottentomatoes.com/m/pain_hustlers"],
        "https://www.rottentomatoes.com/m/killers_of_the_flower_moon": ["https://www.rottentomatoes.com/m/boston_strangler_2023"],
        "https://www.rottentomatoes.com/m/pain_hustlers": ["https://www.rottentomatoes.com/m/boston_strangler_2023", "https://www.rottentomatoes.com/m/killers_of_the_flower_moon"],
        "https://www.rottentomatoes.com/m/reptile_2023": []
    }

    # Create the adjacency matrix
    adjacency_matrix = create_adjacency_matrix(urls, links)

    # Calculate the PageRank
    page_rank = calculate_page_rank(adjacency_matrix)

    # Display the PageRank
    for url, rank in zip(urls, page_rank):
        print(f"{url}: {rank}")

    # Draw the graph of interconnections
    draw_graph(urls, links, page_rank)
